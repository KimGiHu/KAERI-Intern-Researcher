{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2019 NVIDIA Corporation\n",
      "Built on Wed_Oct_23_19:32:27_Pacific_Daylight_Time_2019\n",
      "Cuda compilation tools, release 10.2, V10.2.89\n"
     ]
    }
   ],
   "source": [
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.10.0+cu102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\김기후\\KimGihu\\my_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import numpy as np\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from tqdm import tqdm\n",
    "from torchvision.utils import save_image,make_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "dataset_path = './datasets'\n",
    "\n",
    "cuda = True\n",
    "DEVICE = torch.device(\"cuda\" if cuda else \"cpu\")\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper-parameter\n",
    "batch_size = 100\n",
    "x_dim = 28*28\n",
    "hidden_dim = 400\n",
    "latent_dim = 200\n",
    "\n",
    "lr = 1e-3\n",
    "epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD or Download Dataset\n",
    "from torchvision.datasets import MNIST\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "mnist_transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True}\n",
    "\n",
    "train_dataset = MNIST(dataset_path, transform=mnist_transform, train=True, download=True)\n",
    "test_dataset = MNIST(dataset_path, transform=mnist_transform, train=False, download=True)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, **kwargs)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoEncoder (AE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(28*28, 100),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(100,50),\n",
    "            nn.ReLU(True), nn.Linear(50, 12), nn.ReLU(True), nn.Linear(12, 3)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(3,12),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(12,50),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(50,100),\n",
    "            nn.ReLU(True), nn.Linear(100, 28*28), nn.Tanh()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x_ = self.decoder(x)\n",
    "        x_hat = torch.sigmoid(x_)\n",
    "        return x_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ae = autoencoder().to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "criterion_AE = nn.BCELoss()\n",
    "optimizer_AE = Adam(model_ae.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function_ae(x_hat, x):\n",
    "    reproduction_loss_ae = nn.functional.binary_cross_entropy(x_hat, x, reduction='sum')\n",
    "    return reproduction_loss_ae\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training AE...\n",
      "\tEpoch 1 complete! \tAverage Loss:  321.3773333811561\n",
      "\tEpoch 2 complete! \tAverage Loss:  319.14841614279004\n",
      "\tEpoch 3 complete! \tAverage Loss:  318.0640409145451\n",
      "\tEpoch 4 complete! \tAverage Loss:  317.419023209255\n",
      "\tEpoch 5 complete! \tAverage Loss:  316.8868146455029\n",
      "\tEpoch 6 complete! \tAverage Loss:  316.41113499713066\n",
      "\tEpoch 7 complete! \tAverage Loss:  315.97255080081385\n",
      "\tEpoch 8 complete! \tAverage Loss:  315.615031204351\n",
      "\tEpoch 9 complete! \tAverage Loss:  315.29476138616445\n",
      "\tEpoch 10 complete! \tAverage Loss:  315.02540761294864\n",
      "\tEpoch 11 complete! \tAverage Loss:  314.5937961707012\n",
      "\tEpoch 12 complete! \tAverage Loss:  314.2556358253339\n",
      "\tEpoch 13 complete! \tAverage Loss:  313.8068449042675\n",
      "\tEpoch 14 complete! \tAverage Loss:  313.39843886946994\n",
      "\tEpoch 15 complete! \tAverage Loss:  312.9898349462646\n",
      "\tEpoch 16 complete! \tAverage Loss:  312.60036581150877\n",
      "\tEpoch 17 complete! \tAverage Loss:  312.2504066999687\n",
      "\tEpoch 18 complete! \tAverage Loss:  311.91291318864774\n",
      "\tEpoch 19 complete! \tAverage Loss:  311.5658958289858\n",
      "\tEpoch 20 complete! \tAverage Loss:  311.17067104027547\n",
      "\tEpoch 21 complete! \tAverage Loss:  310.9046499373957\n",
      "\tEpoch 22 complete! \tAverage Loss:  310.6104547618427\n",
      "\tEpoch 23 complete! \tAverage Loss:  310.3827440917154\n",
      "\tEpoch 24 complete! \tAverage Loss:  310.17083893077006\n",
      "\tEpoch 25 complete! \tAverage Loss:  309.91453454324915\n",
      "\tEpoch 26 complete! \tAverage Loss:  309.666988372548\n",
      "\tEpoch 27 complete! \tAverage Loss:  309.5278493126565\n",
      "\tEpoch 28 complete! \tAverage Loss:  309.408075633869\n",
      "\tEpoch 29 complete! \tAverage Loss:  309.2305154097976\n",
      "\tEpoch 30 complete! \tAverage Loss:  309.06984619548206\n",
      "Finish...\n"
     ]
    }
   ],
   "source": [
    "# Train AutoEncoder(AE)\n",
    "print(\"Start training AE...\")\n",
    "model_ae.train()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    overall_loss = 0\n",
    "    for batch_idx, (x, _) in enumerate(train_loader):\n",
    "        # print(x.shape)\n",
    "        x = x.view(batch_size, x_dim)\n",
    "        # print(x.shape)\n",
    "        x = x.to(DEVICE)\n",
    "\n",
    "        # forward\n",
    "        x_hat = model_ae(x)\n",
    "        loss = loss_function_ae(x_hat, x)\n",
    "        \n",
    "        #backward\n",
    "        optimizer_AE.zero_grad()\n",
    "        # print(loss)\n",
    "        overall_loss += loss.item() \n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer_AE.step()\n",
    "        \n",
    "    print(\"\\tEpoch\", epoch + 1, \"complete!\", \"\\tAverage Loss: \", overall_loss / (batch_idx*batch_size))\n",
    "    # print(\"\\tEpoch\", epoch + 1, \"complete!\", \"\\tAverage Loss: \", loss.data[0])\n",
    "\n",
    "\n",
    "print(\"Finish...\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "autoencoder(\n",
       "  (encoder): Sequential(\n",
       "    (0): Linear(in_features=784, out_features=100, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Linear(in_features=100, out_features=50, bias=True)\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): Linear(in_features=50, out_features=12, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=12, out_features=3, bias=True)\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): Linear(in_features=3, out_features=12, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Linear(in_features=12, out_features=50, bias=True)\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): Linear(in_features=50, out_features=100, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=100, out_features=784, bias=True)\n",
       "    (7): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate images from test dataset\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model_ae.eval()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:02<00:00, 45.38it/s]\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for batch_idx, (x, _) in enumerate(tqdm(test_loader)):\n",
    "        x = x.view(batch_size, x_dim)\n",
    "        x = x.to(DEVICE)\n",
    "\n",
    "        x_hat = model_ae(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(x, idx):\n",
    "    x = x.view(batch_size, 28, 28)\n",
    "\n",
    "    fig = plt.figure()\n",
    "    plt.imshow(x[idx].cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_image(x, idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_image(x_hat, idx=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variational AutoEncoder (VAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model : Variational AutoEncoder (VAE)\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, latent_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.FC_input = nn.Linear(input_dim, hidden_dim)\n",
    "        self.FC_input2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.FC_mean = nn.Linear(hidden_dim, latent_dim)\n",
    "        self.FC_var = nn.Linear(hidden_dim, latent_dim)\n",
    "\n",
    "        self.LeakyReLU = nn.LeakyReLU(0.2)\n",
    "\n",
    "        self.training = True\n",
    "\n",
    "    def forward(self, x):\n",
    "        h_ = self.LeakyReLU(self.FC_input(x))\n",
    "        h_ = self.LeakyReLU(self.FC_input2(h_))\n",
    "        mean = self.FC_mean(h_)\n",
    "        log_var = self.FC_var(h_)\n",
    "\n",
    "        return mean, log_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_dim, hidden_dim, output_dim):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.FC_hidden = nn.Linear(latent_dim, hidden_dim)\n",
    "        self.FC_hidden2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.FC_output = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "        self.LeakyReLU = nn.LeakyReLU(0.2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h     = self.LeakyReLU(self.FC_hidden(x))\n",
    "        h     = self.LeakyReLU(self.FC_hidden2(h))\n",
    "        \n",
    "        x_hat = torch.sigmoid(self.FC_output(h))\n",
    "        return x_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, Encoder, Decoder):\n",
    "        super(Model, self).__init__()\n",
    "        self.Encoder = Encoder\n",
    "        self.Decoder = Decoder\n",
    "        \n",
    "    def reparameterization(self, mean, var):\n",
    "        epsilon = torch.randn_like(var).to(DEVICE)        # sampling epsilon        \n",
    "        z = mean + var*epsilon                          # reparameterization trick\n",
    "        return z\n",
    "        \n",
    "                \n",
    "    def forward(self, x):\n",
    "        mean, log_var = self.Encoder(x)\n",
    "        z = self.reparameterization(mean, torch.exp(0.5 * log_var)) # takes exponential function (log var -> var)\n",
    "        x_hat            = self.Decoder(z)\n",
    "        \n",
    "        return x_hat, mean, log_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(input_dim=x_dim, hidden_dim=hidden_dim, latent_dim=latent_dim)\n",
    "decoder = Decoder(latent_dim=latent_dim, hidden_dim = hidden_dim, output_dim = x_dim)\n",
    "\n",
    "model = Model(Encoder=encoder, Decoder=decoder).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Loss Function and optimizer\n",
    "from torch.optim import Adam\n",
    "\n",
    "BCE_loss = nn.BCELoss()\n",
    "\n",
    "def loss_function(x, x_hat, mean, log_var):\n",
    "    reproduction_loss = nn.functional.binary_cross_entropy(x_hat, x, reduction='sum')\n",
    "    KLD      = - 0.5 * torch.sum(1+ log_var - mean.pow(2) - log_var.exp())\n",
    "    return reproduction_loss + KLD\n",
    "\n",
    "\n",
    "optimizer = Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training VAE...\n",
      "tensor(11033.9629, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11033.962890625\n",
      "tensor(10948.9043, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10948.904296875\n",
      "tensor(10884.1582, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10884.158203125\n",
      "tensor(10738.2246, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10738.224609375\n",
      "tensor(10332.3115, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10332.3115234375\n",
      "tensor(10617.2910, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10617.291015625\n",
      "tensor(10754.8633, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10754.86328125\n",
      "tensor(10972.3184, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10972.318359375\n",
      "tensor(10705.0742, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10705.07421875\n",
      "tensor(10969.6855, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10969.685546875\n",
      "tensor(10775.3887, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10775.388671875\n",
      "tensor(10371.9795, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10371.9794921875\n",
      "tensor(10660.4531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10660.453125\n",
      "tensor(10547.4248, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10547.4248046875\n",
      "tensor(10987.0645, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10987.064453125\n",
      "tensor(10266.5762, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10266.576171875\n",
      "tensor(10432.3809, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10432.380859375\n",
      "tensor(10842.9873, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10842.9873046875\n",
      "tensor(10787.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10787.625\n",
      "tensor(11093.5498, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11093.5498046875\n",
      "tensor(10584.3760, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10584.3759765625\n",
      "tensor(10902.4092, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10902.4091796875\n",
      "tensor(10813.8691, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10813.869140625\n",
      "tensor(11015.2939, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11015.2939453125\n",
      "tensor(10572.5498, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10572.5498046875\n",
      "tensor(10798.7988, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10798.798828125\n",
      "tensor(10929.2129, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10929.212890625\n",
      "tensor(10850.4570, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10850.45703125\n",
      "tensor(10780.6289, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10780.62890625\n",
      "tensor(10942.0469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10942.046875\n",
      "tensor(10876.9121, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10876.912109375\n",
      "tensor(10202.0459, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10202.0458984375\n",
      "tensor(10809.7061, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10809.7060546875\n",
      "tensor(10705.3896, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10705.3896484375\n",
      "tensor(10575.8301, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10575.830078125\n",
      "tensor(9964.6611, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9964.6611328125\n",
      "tensor(11362.5762, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11362.576171875\n",
      "tensor(10835.0459, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10835.0458984375\n",
      "tensor(10981.6934, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10981.693359375\n",
      "tensor(11009.7969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11009.796875\n",
      "tensor(10368.9570, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10368.95703125\n",
      "tensor(11089.3047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11089.3046875\n",
      "tensor(10812.3037, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10812.3037109375\n",
      "tensor(9857.6211, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9857.62109375\n",
      "tensor(11476.0918, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11476.091796875\n",
      "tensor(11046.7236, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11046.7236328125\n",
      "tensor(10678.0713, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10678.0712890625\n",
      "tensor(11043.4932, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11043.4931640625\n",
      "tensor(10968.1445, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10968.14453125\n",
      "tensor(10531.5898, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10531.58984375\n",
      "tensor(10411.3047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10411.3046875\n",
      "tensor(10298.8740, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10298.8740234375\n",
      "tensor(10579.9004, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10579.900390625\n",
      "tensor(10725.7109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10725.7109375\n",
      "tensor(10326.1660, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10326.166015625\n",
      "tensor(10805.7266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10805.7265625\n",
      "tensor(10519.9658, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10519.9658203125\n",
      "tensor(10592.3096, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10592.3095703125\n",
      "tensor(10399.9727, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10399.97265625\n",
      "tensor(10263.7793, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10263.779296875\n",
      "tensor(10761.1318, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10761.1318359375\n",
      "tensor(11063.5840, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11063.583984375\n",
      "tensor(10752.2168, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10752.216796875\n",
      "tensor(10545.2959, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10545.2958984375\n",
      "tensor(10976.0186, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10976.0185546875\n",
      "tensor(10837.2773, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10837.27734375\n",
      "tensor(10424.2441, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10424.244140625\n",
      "tensor(10565.2441, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10565.244140625\n",
      "tensor(10515.3496, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10515.349609375\n",
      "tensor(10279.1660, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10279.166015625\n",
      "tensor(10911.4902, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10911.490234375\n",
      "tensor(10757.2363, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10757.236328125\n",
      "tensor(10797.0273, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10797.02734375\n",
      "tensor(10551.5771, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10551.5771484375\n",
      "tensor(11139.1152, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11139.115234375\n",
      "tensor(10214.2148, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10214.21484375\n",
      "tensor(10722.1719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10722.171875\n",
      "tensor(11151.9932, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11151.9931640625\n",
      "tensor(10597.8477, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10597.84765625\n",
      "tensor(10535.3535, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10535.353515625\n",
      "tensor(10280.4326, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10280.4326171875\n",
      "tensor(11752.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11752.25\n",
      "tensor(10894.0195, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10894.01953125\n",
      "tensor(11435.2988, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11435.298828125\n",
      "tensor(10383.7891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10383.7890625\n",
      "tensor(10806.2695, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10806.26953125\n",
      "tensor(10795.1113, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10795.111328125\n",
      "tensor(10649.8916, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10649.8916015625\n",
      "tensor(10892.2275, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10892.2275390625\n",
      "tensor(10689.4727, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10689.47265625\n",
      "tensor(10620.9141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10620.9140625\n",
      "tensor(10828.1016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10828.1015625\n",
      "tensor(10649.5703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10649.5703125\n",
      "tensor(10612.5654, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10612.5654296875\n",
      "tensor(11466.7637, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11466.763671875\n",
      "tensor(10437.3867, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10437.38671875\n",
      "tensor(10679.8105, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10679.810546875\n",
      "tensor(10758.7217, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10758.7216796875\n",
      "tensor(10414.2510, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10414.2509765625\n",
      "tensor(11001.8008, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11001.80078125\n",
      "tensor(10717.1943, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10717.1943359375\n",
      "tensor(10583.7275, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10583.7275390625\n",
      "tensor(10841.6699, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10841.669921875\n",
      "tensor(10435.7793, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10435.779296875\n",
      "tensor(11066.1230, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11066.123046875\n",
      "tensor(10564.9238, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10564.923828125\n",
      "tensor(11058.2676, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11058.267578125\n",
      "tensor(10355.3994, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10355.3994140625\n",
      "tensor(11089.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11089.3125\n",
      "tensor(10441.2383, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10441.23828125\n",
      "tensor(10463.5117, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10463.51171875\n",
      "tensor(11101.0703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11101.0703125\n",
      "tensor(11220.6523, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11220.65234375\n",
      "tensor(10822.1455, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10822.1455078125\n",
      "tensor(10535.7715, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10535.771484375\n",
      "tensor(10617.1006, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10617.1005859375\n",
      "tensor(11005.4355, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11005.435546875\n",
      "tensor(10708.5225, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10708.5224609375\n",
      "tensor(10532.4141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10532.4140625\n",
      "tensor(10253.1387, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10253.138671875\n",
      "tensor(10938.5117, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10938.51171875\n",
      "tensor(11444.5020, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11444.501953125\n",
      "tensor(10854.2695, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10854.26953125\n",
      "tensor(11408.3926, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11408.392578125\n",
      "tensor(10507.5020, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10507.501953125\n",
      "tensor(10609.2979, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10609.2978515625\n",
      "tensor(10389.6064, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10389.6064453125\n",
      "tensor(10269.6885, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10269.6884765625\n",
      "tensor(10781.5938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10781.59375\n",
      "tensor(10411.7217, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10411.7216796875\n",
      "tensor(10638.6309, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10638.630859375\n",
      "tensor(11279.0166, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11279.0166015625\n",
      "tensor(10875.1504, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10875.150390625\n",
      "tensor(10540.0918, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10540.091796875\n",
      "tensor(11363.3350, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11363.3349609375\n",
      "tensor(10396.6465, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10396.646484375\n",
      "tensor(11141.5791, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11141.5791015625\n",
      "tensor(10772.4336, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10772.43359375\n",
      "tensor(10630.3721, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10630.3720703125\n",
      "tensor(11040.7871, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11040.787109375\n",
      "tensor(10597.7871, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10597.787109375\n",
      "tensor(10884.7354, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10884.7353515625\n",
      "tensor(11189.9775, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11189.9775390625\n",
      "tensor(10954.1768, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10954.1767578125\n",
      "tensor(11245.0381, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11245.0380859375\n",
      "tensor(11206.5068, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11206.5068359375\n",
      "tensor(10752.2969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10752.296875\n",
      "tensor(10577.1367, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10577.13671875\n",
      "tensor(10529.1445, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10529.14453125\n",
      "tensor(10294.1143, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10294.1142578125\n",
      "tensor(10550.2207, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10550.220703125\n",
      "tensor(10958.1855, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10958.185546875\n",
      "tensor(10527.3770, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10527.376953125\n",
      "tensor(10980.9307, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10980.9306640625\n",
      "tensor(10983.6055, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10983.60546875\n",
      "tensor(10213.1680, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10213.16796875\n",
      "tensor(10788.3184, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10788.318359375\n",
      "tensor(10874.5410, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10874.541015625\n",
      "tensor(10951.4434, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10951.443359375\n",
      "tensor(10898.3291, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10898.3291015625\n",
      "tensor(10804.5732, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10804.5732421875\n",
      "tensor(10506.0508, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10506.05078125\n",
      "tensor(10913.2832, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10913.283203125\n",
      "tensor(10555.0605, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10555.060546875\n",
      "tensor(10390.2227, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10390.22265625\n",
      "tensor(10902.7344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10902.734375\n",
      "tensor(10687.5889, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10687.5888671875\n",
      "tensor(10332.1074, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10332.107421875\n",
      "tensor(10856.7598, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10856.759765625\n",
      "tensor(10979.4277, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10979.427734375\n",
      "tensor(10745.5381, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10745.5380859375\n",
      "tensor(11430.4766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11430.4765625\n",
      "tensor(11188.2129, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11188.212890625\n",
      "tensor(10159.7207, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10159.720703125\n",
      "tensor(10871.0117, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10871.01171875\n",
      "tensor(10712.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10712.375\n",
      "tensor(10867.0615, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10867.0615234375\n",
      "tensor(10592.3906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10592.390625\n",
      "tensor(11288.5156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11288.515625\n",
      "tensor(10463.7305, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10463.73046875\n",
      "tensor(10734.3223, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10734.322265625\n",
      "tensor(10784.7754, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10784.775390625\n",
      "tensor(10723.0273, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10723.02734375\n",
      "tensor(10958.4541, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10958.4541015625\n",
      "tensor(11024.6670, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11024.6669921875\n",
      "tensor(11072.2510, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11072.2509765625\n",
      "tensor(11214.7158, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11214.7158203125\n",
      "tensor(11075.0898, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11075.08984375\n",
      "tensor(10999.8027, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10999.802734375\n",
      "tensor(10276.2158, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10276.2158203125\n",
      "tensor(10432.6631, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10432.6630859375\n",
      "tensor(10922.9854, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10922.9853515625\n",
      "tensor(10342.3672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10342.3671875\n",
      "tensor(11046.6094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11046.609375\n",
      "tensor(11048.7275, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11048.7275390625\n",
      "tensor(10653.1133, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10653.11328125\n",
      "tensor(10304.8213, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10304.8212890625\n",
      "tensor(10852.3027, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10852.302734375\n",
      "tensor(10341.8506, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10341.8505859375\n",
      "tensor(11176.8262, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11176.826171875\n",
      "tensor(10852.3906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10852.390625\n",
      "tensor(10892.8574, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10892.857421875\n",
      "tensor(10683.5156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10683.515625\n",
      "tensor(10947.2695, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10947.26953125\n",
      "tensor(10434.9014, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10434.9013671875\n",
      "tensor(10960.4434, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10960.443359375\n",
      "tensor(10575.1670, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10575.1669921875\n",
      "tensor(10937.6582, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10937.658203125\n",
      "tensor(10748.6426, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10748.642578125\n",
      "tensor(10994.2188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10994.21875\n",
      "tensor(11228.8564, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11228.8564453125\n",
      "tensor(10574.2520, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10574.251953125\n",
      "tensor(10630.0283, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10630.0283203125\n",
      "tensor(10735.7783, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10735.7783203125\n",
      "tensor(10668.6875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10668.6875\n",
      "tensor(10789.3906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10789.390625\n",
      "tensor(10535.7676, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10535.767578125\n",
      "tensor(11071.5352, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11071.53515625\n",
      "tensor(11234.6455, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11234.6455078125\n",
      "tensor(11079.8135, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11079.8134765625\n",
      "tensor(10737.1475, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10737.1474609375\n",
      "tensor(10709.5615, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10709.5615234375\n",
      "tensor(10618.5322, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10618.5322265625\n",
      "tensor(10633.6270, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10633.626953125\n",
      "tensor(10814.3828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10814.3828125\n",
      "tensor(11042.3652, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11042.365234375\n",
      "tensor(10718.3145, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10718.314453125\n",
      "tensor(10622.8096, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10622.8095703125\n",
      "tensor(10856.1426, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10856.142578125\n",
      "tensor(10603.4453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10603.4453125\n",
      "tensor(10861.8857, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10861.8857421875\n",
      "tensor(10927.1934, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10927.193359375\n",
      "tensor(11053.0811, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11053.0810546875\n",
      "tensor(10897.6406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10897.640625\n",
      "tensor(10803.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10803.625\n",
      "tensor(11195.0635, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11195.0634765625\n",
      "tensor(10788.1338, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10788.1337890625\n",
      "tensor(11135.2617, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11135.26171875\n",
      "tensor(11233.0547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11233.0546875\n",
      "tensor(10747.7217, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10747.7216796875\n",
      "tensor(10877.9297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10877.9296875\n",
      "tensor(10754.5176, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10754.517578125\n",
      "tensor(10870.2314, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10870.2314453125\n",
      "tensor(10551.3105, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10551.310546875\n",
      "tensor(10758.4688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10758.46875\n",
      "tensor(10716.5859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10716.5859375\n",
      "tensor(10902.0605, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10902.060546875\n",
      "tensor(10680.0469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10680.046875\n",
      "tensor(10367.1504, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10367.150390625\n",
      "tensor(11175.0068, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11175.0068359375\n",
      "tensor(10748.7109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10748.7109375\n",
      "tensor(11344.7236, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11344.7236328125\n",
      "tensor(10713.3848, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10713.384765625\n",
      "tensor(10448.8936, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10448.8935546875\n",
      "tensor(10814.7207, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10814.720703125\n",
      "tensor(10750.8770, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10750.876953125\n",
      "tensor(10089.2969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10089.296875\n",
      "tensor(10842.5215, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10842.521484375\n",
      "tensor(10951.3408, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10951.3408203125\n",
      "tensor(10647.0273, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10647.02734375\n",
      "tensor(10350.2529, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10350.2529296875\n",
      "tensor(10986.9023, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10986.90234375\n",
      "tensor(10768.0127, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10768.0126953125\n",
      "tensor(10528.0039, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10528.00390625\n",
      "tensor(10527.5605, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10527.560546875\n",
      "tensor(11161.9912, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11161.9912109375\n",
      "tensor(10919.9824, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10919.982421875\n",
      "tensor(10603.5430, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10603.54296875\n",
      "tensor(10151.5078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10151.5078125\n",
      "tensor(10997.5088, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10997.5087890625\n",
      "tensor(10455.2695, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10455.26953125\n",
      "tensor(10314.0850, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10314.0849609375\n",
      "tensor(11050.7783, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11050.7783203125\n",
      "tensor(10967.4502, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10967.4501953125\n",
      "tensor(11136.1924, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11136.1923828125\n",
      "tensor(10731.0020, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10731.001953125\n",
      "tensor(10504.8730, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10504.873046875\n",
      "tensor(10163.7852, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10163.78515625\n",
      "tensor(10314.8047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10314.8046875\n",
      "tensor(10743.7744, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10743.7744140625\n",
      "tensor(10341.5967, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10341.5966796875\n",
      "tensor(10592.8105, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10592.810546875\n",
      "tensor(10617.6133, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10617.61328125\n",
      "tensor(10578.2461, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10578.24609375\n",
      "tensor(10435.3877, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10435.3876953125\n",
      "tensor(10757.5762, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10757.576171875\n",
      "tensor(10736.5186, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10736.5185546875\n",
      "tensor(10733.8877, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10733.8876953125\n",
      "tensor(10887.5439, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10887.5439453125\n",
      "tensor(10847.3457, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10847.345703125\n",
      "tensor(10451.2422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10451.2421875\n",
      "tensor(10809.7383, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10809.73828125\n",
      "tensor(10785.7773, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10785.77734375\n",
      "tensor(11137.3770, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11137.376953125\n",
      "tensor(10892.4668, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10892.466796875\n",
      "tensor(10785.4121, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10785.412109375\n",
      "tensor(10697.0498, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10697.0498046875\n",
      "tensor(10711.5215, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10711.521484375\n",
      "tensor(9973.2930, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9973.29296875\n",
      "tensor(10712.8242, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10712.82421875\n",
      "tensor(10560.3145, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10560.314453125\n",
      "tensor(10666.8633, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10666.86328125\n",
      "tensor(10610.4180, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10610.41796875\n",
      "tensor(11126.0898, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11126.08984375\n",
      "tensor(10764.7373, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10764.7373046875\n",
      "tensor(10981.1191, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10981.119140625\n",
      "tensor(10907.7578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10907.7578125\n",
      "tensor(10716.4180, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10716.41796875\n",
      "tensor(11135.6699, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11135.669921875\n",
      "tensor(10695.6992, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10695.69921875\n",
      "tensor(10761.5469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10761.546875\n",
      "tensor(10461.2930, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10461.29296875\n",
      "tensor(10771.2910, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10771.291015625\n",
      "tensor(10668.5312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10668.53125\n",
      "tensor(11092.2363, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11092.236328125\n",
      "tensor(10860.1729, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10860.1728515625\n",
      "tensor(10665.1221, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10665.1220703125\n",
      "tensor(10977.4883, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10977.48828125\n",
      "tensor(10379.4053, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10379.4052734375\n",
      "tensor(10960.8682, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10960.8681640625\n",
      "tensor(11171.9453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11171.9453125\n",
      "tensor(10771.3965, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10771.396484375\n",
      "tensor(10709.5293, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10709.529296875\n",
      "tensor(10881.0557, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10881.0556640625\n",
      "tensor(10540.1533, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10540.1533203125\n",
      "tensor(10946.5146, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10946.5146484375\n",
      "tensor(10570.4551, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10570.455078125\n",
      "tensor(10685.5957, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10685.595703125\n",
      "tensor(10913.7881, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10913.7880859375\n",
      "tensor(10823.8516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10823.8515625\n",
      "tensor(10964.0098, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10964.009765625\n",
      "tensor(10961.2266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10961.2265625\n",
      "tensor(10655.5586, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10655.55859375\n",
      "tensor(10384.5928, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10384.5927734375\n",
      "tensor(10746.0430, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10746.04296875\n",
      "tensor(10224.9648, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10224.96484375\n",
      "tensor(10604.6816, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10604.681640625\n",
      "tensor(10633.1074, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10633.107421875\n",
      "tensor(10179.5645, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10179.564453125\n",
      "tensor(10946.2764, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10946.2763671875\n",
      "tensor(10795.2734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10795.2734375\n",
      "tensor(10667.1152, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10667.115234375\n",
      "tensor(11250.3145, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11250.314453125\n",
      "tensor(9909.6445, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9909.64453125\n",
      "tensor(10596.3350, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10596.3349609375\n",
      "tensor(10999.0605, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10999.060546875\n",
      "tensor(10571.0508, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10571.05078125\n",
      "tensor(10821.7217, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10821.7216796875\n",
      "tensor(10704.3496, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10704.349609375\n",
      "tensor(10877.4131, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10877.4130859375\n",
      "tensor(10347.2686, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10347.2685546875\n",
      "tensor(11264.1211, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11264.12109375\n",
      "tensor(11098.9170, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11098.9169921875\n",
      "tensor(10812.9775, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10812.9775390625\n",
      "tensor(10783.9434, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10783.943359375\n",
      "tensor(10997.9053, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10997.9052734375\n",
      "tensor(11076.5615, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11076.5615234375\n",
      "tensor(10750.1074, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10750.107421875\n",
      "tensor(11262.0020, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11262.001953125\n",
      "tensor(10840.1543, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10840.154296875\n",
      "tensor(11278.9443, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11278.9443359375\n",
      "tensor(11351.4775, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11351.4775390625\n",
      "tensor(10582.0039, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10582.00390625\n",
      "tensor(10834.1387, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10834.138671875\n",
      "tensor(11044.9512, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11044.951171875\n",
      "tensor(11043.5127, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11043.5126953125\n",
      "tensor(10655.5752, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10655.5751953125\n",
      "tensor(10507.1348, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10507.134765625\n",
      "tensor(10955.5254, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10955.525390625\n",
      "tensor(10498.1270, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10498.126953125\n",
      "tensor(10793.4453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10793.4453125\n",
      "tensor(10522.2832, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10522.283203125\n",
      "tensor(10670.1924, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10670.1923828125\n",
      "tensor(10279.7637, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10279.763671875\n",
      "tensor(10515.2598, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10515.259765625\n",
      "tensor(10598.8145, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10598.814453125\n",
      "tensor(10696.0225, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10696.0224609375\n",
      "tensor(10331.9668, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10331.966796875\n",
      "tensor(10151.7324, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10151.732421875\n",
      "tensor(10381.9512, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10381.951171875\n",
      "tensor(11053.2266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11053.2265625\n",
      "tensor(10560.8633, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10560.86328125\n",
      "tensor(10607.2178, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10607.2177734375\n",
      "tensor(10823.5312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10823.53125\n",
      "tensor(10827.3887, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10827.388671875\n",
      "tensor(10665.3604, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10665.3603515625\n",
      "tensor(11009.2471, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11009.2470703125\n",
      "tensor(10647.9346, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10647.9345703125\n",
      "tensor(10470.3262, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10470.326171875\n",
      "tensor(10830.7637, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10830.763671875\n",
      "tensor(10259.8369, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10259.8369140625\n",
      "tensor(10946.8213, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10946.8212890625\n",
      "tensor(10358.5996, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10358.599609375\n",
      "tensor(10835.7715, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10835.771484375\n",
      "tensor(10453.4795, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10453.4794921875\n",
      "tensor(10700.4102, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10700.41015625\n",
      "tensor(10894.3584, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10894.3583984375\n",
      "tensor(10546.7793, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10546.779296875\n",
      "tensor(10928.9902, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10928.990234375\n",
      "tensor(10839.2451, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10839.2451171875\n",
      "tensor(10536.9541, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10536.9541015625\n",
      "tensor(10312.6875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10312.6875\n",
      "tensor(10665.5469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10665.546875\n",
      "tensor(10467.3164, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10467.31640625\n",
      "tensor(10920.9258, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10920.92578125\n",
      "tensor(11197.0430, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11197.04296875\n",
      "tensor(10975.0469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10975.046875\n",
      "tensor(10838.1680, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10838.16796875\n",
      "tensor(10739.6670, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10739.6669921875\n",
      "tensor(10609.1406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10609.140625\n",
      "tensor(10865.6055, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10865.60546875\n",
      "tensor(11085.6016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11085.6015625\n",
      "tensor(11374.8418, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11374.841796875\n",
      "tensor(10829.4473, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10829.447265625\n",
      "tensor(10558.8018, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10558.8017578125\n",
      "tensor(10598.9365, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10598.9365234375\n",
      "tensor(11228.0840, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11228.083984375\n",
      "tensor(11142.4170, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11142.4169921875\n",
      "tensor(10887.3164, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10887.31640625\n",
      "tensor(10661.6084, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10661.6083984375\n",
      "tensor(10130.6348, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10130.634765625\n",
      "tensor(11090.9648, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11090.96484375\n",
      "tensor(11099.6064, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11099.6064453125\n",
      "tensor(10634.0938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10634.09375\n",
      "tensor(10042.2676, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10042.267578125\n",
      "tensor(11249.0469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11249.046875\n",
      "tensor(10624.6914, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10624.69140625\n",
      "tensor(10692.5352, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10692.53515625\n",
      "tensor(11026.2734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11026.2734375\n",
      "tensor(10919.1797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10919.1796875\n",
      "tensor(10553.4658, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10553.4658203125\n",
      "tensor(10454.8926, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10454.892578125\n",
      "tensor(10822.2422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10822.2421875\n",
      "tensor(10438.8516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10438.8515625\n",
      "tensor(10598.2480, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10598.248046875\n",
      "tensor(10566.8086, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10566.80859375\n",
      "tensor(11039.8438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11039.84375\n",
      "tensor(10919.8018, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10919.8017578125\n",
      "tensor(10944.0322, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10944.0322265625\n",
      "tensor(10350.6641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10350.6640625\n",
      "tensor(10651.8545, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10651.8544921875\n",
      "tensor(10828.6162, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10828.6162109375\n",
      "tensor(10887.9482, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10887.9482421875\n",
      "tensor(10544.9424, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10544.9423828125\n",
      "tensor(10973.4629, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10973.462890625\n",
      "tensor(10490.1953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10490.1953125\n",
      "tensor(10536.7793, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10536.779296875\n",
      "tensor(10792.8340, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10792.833984375\n",
      "tensor(10136.5957, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10136.595703125\n",
      "tensor(10511.2402, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10511.240234375\n",
      "tensor(10863.4902, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10863.490234375\n",
      "tensor(10232.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10232.75\n",
      "tensor(10356.4932, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10356.4931640625\n",
      "tensor(10799.7227, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10799.72265625\n",
      "tensor(10259.8711, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10259.87109375\n",
      "tensor(10886.1172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10886.1171875\n",
      "tensor(10778.3193, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10778.3193359375\n",
      "tensor(10319.8906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10319.890625\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m overall_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (x, _) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[1;32m----> 8\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_dim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mto(DEVICE)\n\u001b[0;32m     11\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train Variational AutoEncoder(VAE)\n",
    "print(\"Start training VAE...\")\n",
    "model.train()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    overall_loss = 0\n",
    "    for batch_idx, (x, _) in enumerate(train_loader):\n",
    "        x = x.view(batch_size, x_dim)\n",
    "        x = x.to(DEVICE)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        x_hat, mean, log_var = model(x)\n",
    "        loss = loss_function(x, x_hat, mean, log_var)\n",
    "        print(loss)\n",
    "        print(loss.item())\n",
    "        overall_loss += loss.item()\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    print(\"\\tEpoch\", epoch + 1, \"complete!\", \"\\tAverage Loss: \", overall_loss / (batch_idx*batch_size))\n",
    "    \n",
    "print(\"Finish..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (Encoder): Encoder(\n",
       "    (FC_input): Linear(in_features=784, out_features=400, bias=True)\n",
       "    (FC_input2): Linear(in_features=400, out_features=400, bias=True)\n",
       "    (FC_mean): Linear(in_features=400, out_features=200, bias=True)\n",
       "    (FC_var): Linear(in_features=400, out_features=200, bias=True)\n",
       "    (LeakyReLU): LeakyReLU(negative_slope=0.2)\n",
       "  )\n",
       "  (Decoder): Decoder(\n",
       "    (FC_hidden): Linear(in_features=200, out_features=400, bias=True)\n",
       "    (FC_hidden2): Linear(in_features=400, out_features=400, bias=True)\n",
       "    (FC_output): Linear(in_features=400, out_features=784, bias=True)\n",
       "    (LeakyReLU): LeakyReLU(negative_slope=0.2)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate images from test dataset\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model.eval()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:02<00:00, 49.96it/s]\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for batch_idx, (x, _) in enumerate(tqdm(test_loader)):\n",
    "        x = x.view(batch_size, x_dim)\n",
    "        x = x.to(DEVICE)\n",
    "\n",
    "        x_hat, _, _ = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(x, idx):\n",
    "    x = x.view(batch_size, 28, 28)\n",
    "\n",
    "    fig = plt.figure()\n",
    "    plt.imshow(x[idx].cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_image(x, idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_image(x_hat, idx=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conditional Variational Auto-Encoder (CVAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(labels, class_size):\n",
    "    targets = torch.zeros(labels.size(0), class_size)\n",
    "    for i, label in enumerate(labels):\n",
    "        targets[i, label] = 1\n",
    "    return targets.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CVAE(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, latent_dim, class_size):\n",
    "        super(CVAE, self).__init__()\n",
    "        self.feature_size = input_dim\n",
    "        self.class_size = class_size\n",
    "\n",
    "        # encoder \n",
    "        self.fc1 = nn.Linear(self.feature_size + self.class_size, hidden_dim)\n",
    "        self.fc21 = nn.Linear(400, latent_dim)\n",
    "        self.fc22 = nn.Linear(400, latent_dim)\n",
    "\n",
    "        # decoder\n",
    "        self.fc3 = nn.Linear(latent_dim + class_size, 400)\n",
    "        self.fc4 = nn.Linear(400, input_dim)\n",
    "\n",
    "        self.elu = nn.ELU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def encoder(self, x, c): # Q(z|x, c)\n",
    "        \"\"\"\n",
    "        x:(bs, feature_size)\n",
    "        c:(bs, class_size)\n",
    "        \"\"\"\n",
    "        inputs = torch.cat([x,c], 1) # (bs, input_dim + class_size)\n",
    "        h1 = self.elu(self.fc1(inputs))\n",
    "        z_mu = self.fc21(h1)\n",
    "        z_var = self.fc22(h1)\n",
    "        return z_mu, z_var\n",
    "    \n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5*logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps*std\n",
    "    \n",
    "    def decoder(self, z, c): # P(x|z, c)\n",
    "        '''\n",
    "        z : (bs, latent_size)\n",
    "        c : (bs, class_size)\n",
    "        '''\n",
    "        inputs = torch.cat([z,c], 1) # (bs, latent_dim + class_size)\n",
    "        h3 = self.elu(self.fc3(inputs))\n",
    "        return self.sigmoid(self.fc4(h3))\n",
    "    \n",
    "    def forward(self, x, c):\n",
    "        mu, logvar = self.encoder(x.view(-1, 28*28), c)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return self.decoder(z, c), mu, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to create a CVAE model\n",
    "num_classes = 10\n",
    "model_CVAE = CVAE(28*28, hidden_dim, latent_dim, num_classes).to(DEVICE)\n",
    "\n",
    "optimizer_CVAE = optim.Adam(model_CVAE.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function_CVAE(x_hat, x, mu, logvar):\n",
    "    BCE = F.binary_cross_entropy(x_hat, x, x.view(-1,784), reduction='sum')\n",
    "    KLD = -0.5 * torch.sum(1+ logvar - mu.pow(2) - logvar.exp())\n",
    "    return BCE + KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.array(['+ CB V High Fault', '+ DC I High Fault', 'A FLUX High Fault',\n",
    " 'A FLUX Low Fault', 'A+ Driver Fault', 'A- Driver Fault', 'A-* Driver Fault',\n",
    " 'B FLUX Low Fault', 'C FLUX Low Fault', 'C+* Driver Fault',\n",
    " 'DV/DT High Fault', 'DV/DT Low Fault', 'Dump Switch Fault', 'Fiber Fault',\n",
    " 'Gate Duty Cycl Fault', 'MOD I High Fault', 'Oil Level High Fault',\n",
    " 'SCR AC Input Fault', 'SCR Contactor Fault', 'SCR Firing Circ Fault',\n",
    " 'SNS PPS Missing', 'TPS Fault'])\n",
    "\n",
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
